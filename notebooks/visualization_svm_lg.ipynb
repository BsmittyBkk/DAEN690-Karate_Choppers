{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffa9175",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM) Model Analysis Walkthrough (Low Gravity)\n",
    "\n",
    "Support Vector Machines (SVM) are supervised machine learning models that aim to find the hyperplane that best divides a dataset into classes. The core concept is to maximize the margin between the classes. The SVM searches for the closest points (support vectors) and attempts to set the boundary in the middle of them. SVMs can also be used for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db48341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, make_scorer, recall_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc2ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the path to your pickle file (should be the same location as CSVs)\n",
    "path = Path('../data')\n",
    "\n",
    "with open(path / 'low_g_pandas_2.0.2.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251fe102",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "We begin by splitting our dataset into a training and testing set. This process ensures that we have a distinct set of data to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5bae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define independent variables and dependent variable\n",
    "maneuver = 'LOW-G'\n",
    "X = df.drop(maneuver, axis=1)\n",
    "y = df[maneuver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d57a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29bdbd0",
   "metadata": {},
   "source": [
    "## Build and Fit the Model\n",
    "We will set up a parameter grid with the best parameters. These parameters were developed in the modeling directory in the decision tree (LOW-G) file. For more information on the training and tuning of this model please refer to the modeling file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b283a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21223c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid for finding the best hyperparameters\n",
    "params = {\n",
    "    'svm__gamma': [1],\n",
    "    'svm__C': [1000],\n",
    "    'svm__kernel': ['rbf'],\n",
    "    'svm__class_weight': ['balanced'],\n",
    "    'svm__random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dded16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;svm&#x27;, SVC())]),\n",
       "             param_grid={&#x27;svm__C&#x27;: [1000], &#x27;svm__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;svm__gamma&#x27;: [1], &#x27;svm__kernel&#x27;: [&#x27;rbf&#x27;],\n",
       "                         &#x27;svm__random_state&#x27;: [42]},\n",
       "             scoring=make_scorer(f1_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;svm&#x27;, SVC())]),\n",
       "             param_grid={&#x27;svm__C&#x27;: [1000], &#x27;svm__class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;svm__gamma&#x27;: [1], &#x27;svm__kernel&#x27;: [&#x27;rbf&#x27;],\n",
       "                         &#x27;svm__random_state&#x27;: [42]},\n",
       "             scoring=make_scorer(f1_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;svm&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('svm', SVC())]),\n",
       "             param_grid={'svm__C': [1000], 'svm__class_weight': ['balanced'],\n",
       "                         'svm__gamma': [1], 'svm__kernel': ['rbf'],\n",
       "                         'svm__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search with cross-validation\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# instantiate the grid search loading pipeline, parameters, k-fold, and scorer\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=params, cv=strat_k_fold, scoring=f1_scorer)\n",
    "# fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c6b79",
   "metadata": {},
   "source": [
    "## Make Predictions for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b760b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9999    1.0000     51437\n",
      "           1     0.9914    1.0000    0.9957       344\n",
      "\n",
      "    accuracy                         0.9999     51781\n",
      "   macro avg     0.9957    1.0000    0.9978     51781\n",
      "weighted avg     0.9999    0.9999    0.9999     51781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a05aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51434     3]\n",
      " [    0   344]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ab9d5",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "These visualizations will provide a comprehensive understanding of the model's performance, the features that drive decisions, and how the model's performance evolves as more data is added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60c3bf",
   "metadata": {},
   "source": [
    "### Exploring C Values\n",
    "The 'C' parameter in SVMs determines the trade-off between achieving a low error on the training data and maximizing the margin between classes. Let's see how different values of 'C' impact our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b5b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n",
      "[1.0]\n",
      "[1.0]\n",
      "[0.05649717514124294]\n",
      "[0.029069767441860465]\n",
      "[1.0]\n",
      "f1: >0, train: 1.000, test: 0.056\n",
      "recall: >0, train: 1.000, test: 0.029\n",
      "precision: >0, train: 1.000, test: 1.000\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[0.05649717514124294, 0.05649717514124294]\n",
      "[0.029069767441860465, 0.029069767441860465]\n",
      "[1.0, 1.0]\n",
      "f1: >1, train: 1.000, test: 0.056\n",
      "recall: >1, train: 1.000, test: 0.029\n",
      "precision: >1, train: 1.000, test: 1.000\n"
     ]
    }
   ],
   "source": [
    "# C Values\n",
    "\n",
    "# define lists to collect scores\n",
    "train_f1_scores, test_f1_scores = list(), list()\n",
    "train_recall_scores, test_recall_scores = list(), list()\n",
    "train_prec_scores, test_prec_scores = list(), list()\n",
    "\n",
    "# define list of C values to plot\n",
    "c_values = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for c in c_values:\n",
    "    # configure the model\n",
    "    model = SVC(kernel='rbf', gamma=1, C=c, class_weight='balanced', random_state=42)\n",
    "    # fit the training dataset\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    # evaluate training dataset\n",
    "    train_yhat = model.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, train_yhat)\n",
    "    train_recall = recall_score(y_train, train_yhat)\n",
    "    train_prec = precision_score(y_train, train_yhat)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    print(train_f1_scores)\n",
    "    train_recall_scores.append(train_recall)\n",
    "    print(train_recall_scores)\n",
    "    train_prec_scores.append(train_prec)\n",
    "    print(train_prec_scores)\n",
    "    # evaluate test dataset\n",
    "    test_yhat = model.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, test_yhat)\n",
    "    test_recall = recall_score(y_test, test_yhat)\n",
    "    test_prec = precision_score(y_test, test_yhat)\n",
    "    test_f1_scores.append(test_f1)\n",
    "    print(test_f1_scores)\n",
    "    test_recall_scores.append(test_recall)\n",
    "    print(test_recall_scores)\n",
    "    test_prec_scores.append(test_prec)\n",
    "    print(test_prec_scores)    \n",
    "    # summarize progress\n",
    "    print('f1: >%d, train: %.3f, test: %.3f' % (c, train_f1, test_f1))\n",
    "    print('recall: >%d, train: %.3f, test: %.3f' % (c, train_recall, test_recall))\n",
    "    print('precision: >%d, train: %.3f, test: %.3f' % (c, train_prec, test_prec))\n",
    "\n",
    "train_f1_scores\n",
    "test_f1_scores\n",
    "\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(c_values, test_f1_scores, '-o', label='f1 score')\n",
    "plt.plot(c_values, test_recall_scores, '-o', label='recall')\n",
    "plt.plot(c_values, test_prec_scores, '-o', label='precision')\n",
    "plt.title(\"C Values\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"C Value (Gamma = 1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Gamma Values\n",
    "\n",
    "The gamma parameter is specific to the 'rbf' kernel in SVMs. It defines how far the influence of a single training example reaches. A low gamma means ‘far’ while a high gamma means ‘close’. Let's visualize its impact on our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35745a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma Values\n",
    "\n",
    "# define lists to collect scores\n",
    "train_f1_scores, test_f1_scores = list(), list()\n",
    "train_recall_scores, test_recall_scores = list(), list()\n",
    "train_prec_scores, test_prec_scores = list(), list()\n",
    "\n",
    "# define list of C values to plot\n",
    "gamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for g in gamma_values:\n",
    "    # configure the model\n",
    "    model = SVC(kernel='rbf', gamma=g, C=1000, class_weight='balanced', random_state=42)\n",
    "    # fit the training dataset\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    # evaluate training dataset\n",
    "    train_yhat = model.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, train_yhat)\n",
    "    train_recall = recall_score(y_train, train_yhat)\n",
    "    train_prec = precision_score(y_train, train_yhat)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    print(train_f1_scores)\n",
    "    train_recall_scores.append(train_recall)\n",
    "    print(train_recall_scores)\n",
    "    train_prec_scores.append(train_prec)\n",
    "    print(train_prec_scores)\n",
    "    # evaluate test dataset\n",
    "    test_yhat = model.predict(x_test)\n",
    "    test_f1 = f1_score(y_test, test_yhat)\n",
    "    test_recall = recall_score(y_test, test_yhat)\n",
    "    test_prec = precision_score(y_test, test_yhat)\n",
    "    test_f1_scores.append(test_f1)\n",
    "    print(test_f1_scores)\n",
    "    test_recall_scores.append(test_recall)\n",
    "    print(test_recall_scores)\n",
    "    test_prec_scores.append(test_prec)\n",
    "    print(test_prec_scores)    \n",
    "    # summarize progress\n",
    "    print('f1: >%d, train: %.3f, test: %.3f' % (g, train_f1, test_f1))\n",
    "    print('recall: >%d, train: %.3f, test: %.3f' % (g, train_recall, test_recall))\n",
    "    print('precision: >%d, train: %.3f, test: %.3f' % (g, train_prec, test_prec))\n",
    "\n",
    "\n",
    "# plot of train and test scores vs tree depth\n",
    "plt.plot(gamma_values, test_f1_scores, '-o', label='f1 score')\n",
    "plt.plot(gamma_values, test_recall_scores, '-o', label='recall')\n",
    "plt.plot(gamma_values, test_prec_scores, '-o', label='precision')\n",
    "plt.legend()\n",
    "plt.title(\"Gamma Values\")\n",
    "plt.xlabel(\"Gamma Value (C = 1000)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
